## Credit Risk Model

Welcome to the Week 5 project of the **10 Academy Artificial Intelligence Mastery Program**! In this project, we are tasked with building, deploying, and automating a **credit scoring model** using customer transaction data from a partner eCommerce platform. This model will help our client, **Bati Bank**, evaluate customer creditworthiness and enable **buy-now-pay-later (BNPL)** services.

---

### ğŸ“ˆ Business Need

Bati Bank is collaborating with a fast-growing eCommerce provider to offer credit services. The job is to build a machine learning pipeline that can:

1. Define a proxy credit risk variable (no default label exists).
2. Engineer meaningful features from raw behavioral data.
3. Train a model to predict credit risk.
4. Derive credit scores from predicted risk.
5. Suggest optimal loan amounts and durations.
6. Deploy the model as a scalable API with CI/CD and MLOps tools.

---

## ğŸ“‚ Project Structure

```
credit-risk-model/
â”œâ”€â”€ .github/workflows/ci.yml         # CI/CD workflow
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                         # Raw data
â”‚   â””â”€â”€ processed/                   # Cleaned & transformed data
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 1.0-eda.ipynb                # Data exploration & insights
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_processing.py          # Feature engineering logic
â”‚   â”œâ”€â”€ train.py                    # Model training
â”‚   â”œâ”€â”€ predict.py                  # Inference logic
â”‚   â””â”€â”€ api/
â”‚       â”œâ”€â”€ main.py                 # FastAPI application
â”‚       â””â”€â”€ pydantic_models.py      # Request/response validation
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_data_processing.py     # Unit tests
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## âœ… Tasks

### ğŸ§  Task 1: Credit Scoring Business Understanding

In real-world financial systems, interpretability and regulatory compliance are just as important as accuracy. Hereâ€™s what weâ€™ve understood so far:

#### ğŸ“˜ Why Basel II Emphasizes Model Transparency

The **Basel II Accord** requires banks to manage and justify credit risk assessments using internal models that are explainable and auditable. This means we must **build interpretable models** that regulators and auditors can understand, trust, and verify.

#### âš ï¸ Why We Create a Proxy Variable

Our data doesnâ€™t include a `default` label, so we define a **proxy credit risk variable** using customer behavior (Recency, Frequency, Monetary). This proxy lets us predict risk even without direct labels.

But it's important to note:

* The proxy might not reflect actual defaults.
* Mislabeling could hurt financial performance or fairness.
* Weâ€™ll need careful documentation, validation, and performance tracking to reduce risk.

#### âš–ï¸ Trade-offs: Interpretable vs. Complex Models

| Factor              | Logistic Regression with WoE  | Gradient Boosting Models         |
| ------------------- | ----------------------------- | -------------------------------- |
| Interpretability    | Very high                     |   Low                            |
| Performance         | Lower but stable              |   Higher accuracy                |
| Regulation-friendly | Easy to justify               |   Needs heavy explanation        |
| Use case            | First model in regulated bank | Complex relationships and tuning |

---

### ğŸ“Š Task 2: Exploratory Data Analysis (EDA)

* Explore structure, distribution, and key metrics in `1.0-eda.ipynb`
* Identify trends, missing data, and potential outliers
* Summary: Top 3â€“5 insights will guide our feature engineering.

### ğŸ›  Task 3: Feature Engineering

* Create aggregate features (total, mean, std. of transaction amounts)
* Extract datetime features (hour, day, month, year)
* Encode categorical features
* Handle missing data
* Normalize and build pipelines using `scikit-learn`

### ğŸ¯ Task 4: Proxy Target Variable Engineering

* Calculate **RFM (Recency, Frequency, Monetary)** metrics
* Cluster customers with **KMeans** (3 segments)
* Label least active group as `is_high_risk = 1`
* Merge this label into the processed training data

### ğŸ¤– Task 5: Model Training and Tracking

* Try 2+ models (e.g., Logistic Regression, Random Forest, XGBoost)
* Use MLflow for experiment tracking & model registry
* Evaluate using Accuracy, Precision, Recall, F1 Score, and ROC-AUC
* Write unit tests and register the best model

### ğŸš€ Task 6: Model Deployment & CI/CD

* Serve model with **FastAPI** and `uvicorn`
* Build Docker container and `docker-compose` for easy launch
* Add CI/CD pipeline with **GitHub Actions**:

  * Run `flake8` for linting
  * Run `pytest` for testing
* Pipeline blocks if tests or style checks fail

---

## ğŸ“š Learning Outcomes

* ğŸ’¡ Business reasoning with credit risk
* ğŸ§¼ Feature engineering & EDA
* âš™ï¸ Machine learning pipeline development
* ğŸ“¦ Deployment with FastAPI, Docker, GitHub Actions
* ğŸ“Š Experiment tracking with MLflow
* ğŸ” CI/CD, unit testing, logging, and more!
