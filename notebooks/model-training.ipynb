{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ce5c8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5377e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X columns: ['Amount_sum', 'Amount_mean', 'Amount_std', 'Amount_max', 'Amount_min', 'Amount_count', 'Value_sum', 'Value_mean', 'Value_std', 'Value_max', 'Value_min', 'TransactionHour_nunique', 'TransactionDay_nunique', 'TransactionMonth_nunique']\n",
      "Transformed X shape: (3742, 14)\n",
      "Feature extraction complete. Processed data ready for modeling.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"../data/processed/eda_data.csv\")\n",
    "\n",
    "# Feature Engineering\n",
    "agg_df = df.groupby('CustomerId').agg({\n",
    "    'Amount': ['sum', 'mean', 'std', 'max', 'min', 'count'],\n",
    "    'Value': ['sum', 'mean', 'std', 'max', 'min'],\n",
    "    'TransactionHour': 'nunique',\n",
    "    'TransactionDay': 'nunique',\n",
    "    'TransactionMonth': 'nunique'\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "agg_df.columns = ['CustomerId'] + ['_'.join(col).strip() for col in agg_df.columns[1:]]\n",
    "customer_ids = agg_df['CustomerId']\n",
    "\n",
    "num_features = [col for col in agg_df.columns if agg_df[col].dtype in ['int64', 'float64'] and col != 'CustomerId']\n",
    "\n",
    "\n",
    "X = agg_df.drop(columns=['CustomerId'])\n",
    "y = np.zeros(X.shape[0]) \n",
    "\n",
    "print(\"X columns:\", X.columns.tolist())\n",
    "\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Apply transformations\n",
    "X_scaled = numeric_pipeline.fit_transform(X)\n",
    "\n",
    "print(\"Transformed X shape:\", X_scaled.shape)\n",
    "\n",
    "print(\"Feature extraction complete. Processed data ready for modeling.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "093bd242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proxy labels created. High-risk cluster: 0\n",
      "is_high_risk\n",
      "0    2307\n",
      "1    1435\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Task 4 : proxy labels creation\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "\n",
    "df['TransactionStartTime'] = pd.to_datetime(df['TransactionStartTime'], errors='coerce')\n",
    "\n",
    "# Define snapshot date for Recency calculation\n",
    "snapshot_date = df['TransactionStartTime'].max() + pd.Timedelta(days=1)\n",
    "\n",
    "# Calculate RFM per CustomerId\n",
    "rfm = df.groupby('CustomerId').agg({\n",
    "    'TransactionStartTime': lambda x: (snapshot_date - x.max()).days,\n",
    "    'TransactionId': 'count',\n",
    "    'Value': 'sum'\n",
    "}).reset_index()\n",
    "rfm.columns = ['CustomerId', 'Recency', 'Frequency', 'Monetary']\n",
    "\n",
    "# Scale RFM for clustering\n",
    "scaler = StandardScaler()\n",
    "rfm_scaled = scaler.fit_transform(rfm[['Recency', 'Frequency', 'Monetary']])\n",
    "\n",
    "# KMeans Clustering (3 segments)\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "rfm['Cluster'] = kmeans.fit_predict(rfm_scaled)\n",
    "\n",
    "# Determine high-risk cluster: lowest Frequency + Monetary, highest Recency\n",
    "cluster_summary = rfm.groupby('Cluster').agg({\n",
    "    'Recency': 'mean',\n",
    "    'Frequency': 'mean',\n",
    "    'Monetary': 'mean'\n",
    "}).sort_values(by='Frequency')\n",
    "\n",
    "high_risk_cluster = cluster_summary.index[0]  # assume lowest freq is highest risk\n",
    "rfm['is_high_risk'] = (rfm['Cluster'] == high_risk_cluster).astype(int)\n",
    "\n",
    "# Save or merge this label with processed features\n",
    "# e.g. rfm[['CustomerId', 'is_high_risk']] \n",
    "#merge it with df\n",
    "\n",
    "rfm = rfm[['CustomerId', 'is_high_risk']]\n",
    "df = df.merge(rfm, on='CustomerId', how='left')\n",
    "\n",
    "# Save the processed data with proxy labels\n",
    "PROCESSED_DATA_PATH = \"../data/processed/eda_data_with_proxy_labels.csv\"\n",
    "df.to_csv(PROCESSED_DATA_PATH, index=False)\n",
    "\n",
    "print(\"Proxy labels created. High-risk cluster:\", high_risk_cluster)\n",
    "print(rfm['is_high_risk'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7ec7050",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/01 17:59:07 INFO mlflow.tracking.fluent: Experiment with name 'credit-risk-model' does not exist. Creating a new experiment.\n",
      "2025/07/01 17:59:07 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/07/01 17:59:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Successfully registered model 'Logistic_Regression'.\n",
      "Created version '1' of model 'Logistic_Regression'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Logistic Regression Results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.60      0.70       462\n",
      "           1       0.56      0.81      0.66       287\n",
      "\n",
      "    accuracy                           0.68       749\n",
      "   macro avg       0.70      0.70      0.68       749\n",
      "weighted avg       0.73      0.68      0.68       749\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/01 17:59:13 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/07/01 17:59:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Random Forest Results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.80       462\n",
      "           1       0.67      0.70      0.68       287\n",
      "\n",
      "    accuracy                           0.75       749\n",
      "   macro avg       0.74      0.74      0.74       749\n",
      "weighted avg       0.75      0.75      0.75       749\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Random_Forest'.\n",
      "Created version '1' of model 'Random_Forest'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "df_final = pd.DataFrame(X_scaled)\n",
    "df_final['CustomerId'] = customer_ids.values\n",
    "df_final = df_final.merge(rfm[['CustomerId', 'is_high_risk']], on='CustomerId')\n",
    "\n",
    "y = df_final['is_high_risk']\n",
    "X_final = df_final.drop(columns=['CustomerId', 'is_high_risk'])\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Train and Evaluate (Task 5)\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "mlflow.set_experiment(\"credit-risk-model\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    with mlflow.start_run(run_name=name):\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        probs = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        acc = accuracy_score(y_test, preds)\n",
    "        prec = precision_score(y_test, preds)\n",
    "        rec = recall_score(y_test, preds)\n",
    "        f1 = f1_score(y_test, preds)\n",
    "        roc = roc_auc_score(y_test, probs)\n",
    "\n",
    "        mlflow.log_param(\"model\", name)\n",
    "        mlflow.log_metrics({\n",
    "            \"accuracy\": acc,\n",
    "            \"precision\": prec,\n",
    "            \"recall\": rec,\n",
    "            \"f1_score\": f1,\n",
    "            \"roc_auc\": roc\n",
    "        })\n",
    "\n",
    "        mlflow.sklearn.log_model(model, \"model\", registered_model_name=name.replace(\" \", \"_\"))\n",
    "\n",
    "        print(f\"✅ {name} Results\")\n",
    "        print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c12a4066",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/01 17:59:17 INFO mlflow.tracking.fluent: Experiment with name 'credit-risk-model-tuned' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Running GridSearch for Logistic Regression\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/01 17:59:25 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/07/01 17:59:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Successfully registered model 'Logistic_Regression_Tuned'.\n",
      "Created version '1' of model 'Logistic_Regression_Tuned'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Logistic Regression tuned and logged.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.60      0.70       462\n",
      "           1       0.56      0.81      0.66       287\n",
      "\n",
      "    accuracy                           0.68       749\n",
      "   macro avg       0.70      0.70      0.68       749\n",
      "weighted avg       0.73      0.68      0.68       749\n",
      "\n",
      "\n",
      "🔍 Running GridSearch for Random Forest\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/01 17:59:36 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/07/01 17:59:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Random Forest tuned and logged.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.77      0.80       462\n",
      "           1       0.67      0.74      0.70       287\n",
      "\n",
      "    accuracy                           0.76       749\n",
      "   macro avg       0.75      0.76      0.75       749\n",
      "weighted avg       0.77      0.76      0.76       749\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Random_Forest_Tuned'.\n",
      "Created version '1' of model 'Random_Forest_Tuned'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "# Define parameter grids\n",
    "param_grids = {\n",
    "    \"Logistic Regression\": {\n",
    "        'C': [0.01, 0.1, 1, 10],\n",
    "        'penalty': ['l2'],\n",
    "        'solver': ['lbfgs']\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [5, 10, None],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2]\n",
    "    }\n",
    "}\n",
    "\n",
    "mlflow.set_experiment(\"credit-risk-model-tuned\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n🔍 Running GridSearch for {name}\")\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grids[name],\n",
    "        cv=3,\n",
    "        scoring='f1',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    tuned_model = grid_search.best_estimator_\n",
    "    preds = tuned_model.predict(X_test)\n",
    "    probs = tuned_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    prec = precision_score(y_test, preds)\n",
    "    rec = recall_score(y_test, preds)\n",
    "    f1 = f1_score(y_test, preds)\n",
    "    roc = roc_auc_score(y_test, probs)\n",
    "\n",
    "    with mlflow.start_run(run_name=f\"{name} - Tuned\"):\n",
    "        mlflow.log_params(grid_search.best_params_)\n",
    "        mlflow.log_metrics({\n",
    "            \"accuracy\": acc,\n",
    "            \"precision\": prec,\n",
    "            \"recall\": rec,\n",
    "            \"f1_score\": f1,\n",
    "            \"roc_auc\": roc\n",
    "        })\n",
    "        mlflow.sklearn.log_model(tuned_model, \"model\", registered_model_name=name.replace(\" \", \"_\") + \"_Tuned\")\n",
    "        print(f\"✅ {name} tuned and logged.\\n\")\n",
    "        print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d45fa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = mlflow.sklearn.load_model(\"models:/Logistic_Regression_Tuned/1\")\n",
    "mlflow.sklearn.save_model(best_model, \"exported_model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
